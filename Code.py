"""
Code Analyzer (é«˜æ€§èƒ½ãƒãƒ¼ã‚¸ãƒ§ãƒ³)
AliceProjectã®å…¨ã‚³ãƒ¼ãƒ‰ã‚’è§£æã—ã€å“è³ªå‘ä¸Šã®ææ¡ˆã‚’è¡Œã„ã¾ã™

æ©Ÿèƒ½:
- é™çš„ã‚³ãƒ¼ãƒ‰è§£æ
- ã‚³ãƒ¼ãƒ‰å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
- æ½œåœ¨çš„ãªãƒã‚°æ¤œå‡º
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ææ¡ˆ
- ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ãƒã‚§ãƒƒã‚¯
"""

import ast
import sys
from pathlib import Path
from typing import List, Dict, Any, Optional, Set
import json
from dataclasses import dataclass, asdict
from datetime import datetime
import re


@dataclass
class CodeIssue:
    """ã‚³ãƒ¼ãƒ‰å•é¡Œãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    file: str
    line: int
    severity: str  # critical/high/medium/low
    category: str
    message: str
    suggestion: str


@dataclass
class CodeMetrics:
    """ã‚³ãƒ¼ãƒ‰ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    file: str
    lines_of_code: int
    comment_lines: int
    blank_lines: int
    functions: int
    classes: int
    complexity: int
    maintainability_index: float
    max_function_length: int
    imports_count: int


class CodeAnalyzer:
    """ã‚³ãƒ¼ãƒ‰è§£æã‚¯ãƒ©ã‚¹ï¼ˆé«˜æ€§èƒ½ç‰ˆï¼‰"""
    
    # å‹•çš„ã«è¨­å®šå¯èƒ½ãªã—ãã„å€¤
    THRESHOLDS = {
        'max_line_length': 120,
        'max_function_length': 50,
        'max_complexity': 20,
        'min_maintainability': 50,
        'max_function_params': 5,
    }
    
    def __init__(self, project_root: Path):
        """
        åˆæœŸåŒ–
        
        Args:
            project_root: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹
        """
        self.project_root = project_root
        self.issues: List[CodeIssue] = []
        self.metrics: List[CodeMetrics] = []
        self.analysis_result = {}
        self.output_dir = project_root / "code"
        self.output_dir.mkdir(exist_ok=True)
    
    def analyze_project(self) -> Dict[str, Any]:
        """
        ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã‚’è§£æ
        
        Returns:
            è§£æçµæœè¾æ›¸
        """
        print("=" * 70)
        print("ğŸ” Alice Project - Code Analyzer (é«˜æ€§èƒ½ç‰ˆ)")
        print("=" * 70)
        
        # Pythonãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
        py_files = self._get_python_files()
        
        print(f"\nğŸ“ è§£æå¯¾è±¡: {len(py_files)} ãƒ•ã‚¡ã‚¤ãƒ«")
        print(f"ğŸ“‚ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {self.output_dir}\n")
        
        for py_file in py_files:
            print(f"  ğŸ“„ åˆ†æä¸­: {py_file.relative_to(self.project_root)}")
            self._analyze_file(py_file)
        
        # çµæœã‚’ã¾ã¨ã‚ã‚‹
        self._generate_report()
        
        return self.analysis_result
    
    def _get_python_files(self) -> List[Path]:
        """
        è§£æå¯¾è±¡ã®Pythonãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
        
        Returns:
            Pythonãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆ
        """
        py_files = list(self.project_root.rglob("*.py"))
        # é™¤å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³
        exclude_patterns = ['venv', '__pycache__', '.git', 'build', 'dist']
        
        filtered_files = []
        for f in py_files:
            if not any(pattern in str(f) for pattern in exclude_patterns):
                filtered_files.append(f)
        
        return sorted(filtered_files)
    
    def _analyze_file(self, file_path: Path):
        """
        å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æ
        
        Args:
            file_path: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
            metrics = self._calculate_metrics(file_path, content)
            self.metrics.append(metrics)
            
            # å•é¡Œæ¤œå‡º
            self._detect_issues(file_path, content)
            
        except Exception as e:
            print(f"    âš ï¸  è§£æã‚¨ãƒ©ãƒ¼: {e}")
    
    def _calculate_metrics(self, file_path: Path, content: str) -> CodeMetrics:
        """
        ã‚³ãƒ¼ãƒ‰ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨ˆç®—
        
        Args:
            file_path: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            content: ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹
            
        Returns:
            CodeMetricsã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        """
        lines = content.split('\n')
        
        # è¡Œæ•°ã‚«ã‚¦ãƒ³ãƒˆ
        loc = len([l for l in lines if l.strip() and not l.strip().startswith('#')])
        comment_lines = len([l for l in lines if l.strip().startswith('#')])
        blank_lines = len([l for l in lines if not l.strip()])
        
        # ASTè§£æ
        functions = 0
        classes = 0
        complexity = 0
        max_func_length = 0
        imports = 0
        
        try:
            tree = ast.parse(content)
            functions = len([n for n in ast.walk(tree) if isinstance(n, ast.FunctionDef)])
            classes = len([n for n in ast.walk(tree) if isinstance(n, ast.ClassDef)])
            complexity = self._calculate_complexity(tree)
            max_func_length = self._get_max_function_length(tree)
            imports = len([n for n in ast.walk(tree) if isinstance(n, (ast.Import, ast.ImportFrom))])
        except SyntaxError:
            pass
        
        # ä¿å®ˆæ€§æŒ‡æ¨™
        maintainability = self._calculate_maintainability(loc, complexity, comment_lines)
        
        return CodeMetrics(
            file=str(file_path.relative_to(self.project_root)),
            lines_of_code=loc,
            comment_lines=comment_lines,
            blank_lines=blank_lines,
            functions=functions,
            classes=classes,
            complexity=complexity,
            maintainability_index=maintainability,
            max_function_length=max_func_length,
            imports_count=imports
        )
    
    def _calculate_complexity(self, tree: ast.AST) -> int:
        """
        å¾ªç’°çš„è¤‡é›‘åº¦ã‚’è¨ˆç®—ï¼ˆMcCabeè¤‡é›‘åº¦ï¼‰
        
        Args:
            tree: ASTãƒ„ãƒªãƒ¼
            
        Returns:
            è¤‡é›‘åº¦
        """
        complexity = 1
        
        for node in ast.walk(tree):
            if isinstance(node, (ast.If, ast.While, ast.For, ast.ExceptHandler)):
                complexity += 1
            elif isinstance(node, ast.BoolOp):
                complexity += len(node.values) - 1
            elif isinstance(node, (ast.And, ast.Or)):
                complexity += 1
        
        return complexity
    
    def _get_max_function_length(self, tree: ast.AST) -> int:
        """
        æœ€å¤§é–¢æ•°é•·ã‚’å–å¾—
        
        Args:
            tree: ASTãƒ„ãƒªãƒ¼
            
        Returns:
            æœ€å¤§é–¢æ•°é•·
        """
        max_length = 0
        
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                if hasattr(node, 'end_lineno'):
                    length = node.end_lineno - node.lineno
                    max_length = max(max_length, length)
        
        return max_length
    
    def _calculate_maintainability(self, loc: int, complexity: int, comments: int) -> float:
        """
        ä¿å®ˆæ€§æŒ‡æ¨™ã‚’è¨ˆç®—ï¼ˆMaintainability Indexï¼‰
        
        Args:
            loc: ã‚³ãƒ¼ãƒ‰è¡Œæ•°
            complexity: è¤‡é›‘åº¦
            comments: ã‚³ãƒ¡ãƒ³ãƒˆè¡Œæ•°
            
        Returns:
            ä¿å®ˆæ€§æŒ‡æ¨™ï¼ˆ0-100ï¼‰
        """
        if loc == 0:
            return 100.0
        
        # ã‚³ãƒ¡ãƒ³ãƒˆç‡
        comment_ratio = (comments / loc) if loc > 0 else 0
        
        # è¤‡é›‘åº¦ãƒšãƒŠãƒ«ãƒ†ã‚£ï¼ˆæ­£è¦åŒ–ï¼‰
        complexity_penalty = min(complexity / 50, 1.0)
        
        # ã‚³ãƒ¼ãƒ‰é‡ãƒšãƒŠãƒ«ãƒ†ã‚£ï¼ˆå¤§ãã™ãã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
        size_penalty = min(loc / 1000, 1.0) * 0.5
        
        # ä¿å®ˆæ€§ã‚¹ã‚³ã‚¢è¨ˆç®—
        score = 100 - (complexity_penalty * 40) - (size_penalty * 20) + (comment_ratio * 15)
        
        return max(0.0, min(100.0, score))
    
    def _detect_issues(self, file_path: Path, content: str):
        """
        ã‚³ãƒ¼ãƒ‰å•é¡Œã‚’æ¤œå‡º
        
        Args:
            file_path: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            content: ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹
        """
        lines = content.split('\n')
        rel_path = str(file_path.relative_to(self.project_root))
        
        # ASTè§£æã«ã‚ˆã‚‹å•é¡Œæ¤œå‡º
        try:
            tree = ast.parse(content)
            self._detect_ast_issues(tree, rel_path)
        except SyntaxError as e:
            self.issues.append(CodeIssue(
                file=rel_path,
                line=e.lineno if e.lineno else 0,
                severity="critical",
                category="syntax",
                message=f"æ§‹æ–‡ã‚¨ãƒ©ãƒ¼: {e.msg}",
                suggestion="æ§‹æ–‡ã‚’ä¿®æ­£ã—ã¦ãã ã•ã„"
            ))
        
        # ãƒ†ã‚­ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹ã®å•é¡Œæ¤œå‡º
        self._detect_text_issues(lines, rel_path)
    
    def _detect_ast_issues(self, tree: ast.AST, rel_path: str):
        """
        ASTãƒ™ãƒ¼ã‚¹ã®å•é¡Œæ¤œå‡º
        
        Args:
            tree: ASTãƒ„ãƒªãƒ¼
            rel_path: ç›¸å¯¾ãƒ‘ã‚¹
        """
        for node in ast.walk(tree):
            # é•·ã„é–¢æ•°
            if isinstance(node, ast.FunctionDef):
                if hasattr(node, 'end_lineno'):
                    func_lines = node.end_lineno - node.lineno
                    if func_lines > self.THRESHOLDS['max_function_length']:
                        self.issues.append(CodeIssue(
                            file=rel_path,
                            line=node.lineno,
                            severity="medium",
                            category="complexity",
                            message=f"é–¢æ•° '{node.name}' ãŒé•·ã™ãã¾ã™ ({func_lines}è¡Œ > {self.THRESHOLDS['max_function_length']}è¡Œ)",
                            suggestion=f"é–¢æ•°ã‚’{self.THRESHOLDS['max_function_length']}è¡Œä»¥å†…ã«åˆ†å‰²ã—ã¦ãã ã•ã„"
                        ))
                
                # å¼•æ•°ãŒå¤šã™ãã‚‹é–¢æ•°
                num_args = len(node.args.args)
                if num_args > self.THRESHOLDS['max_function_params']:
                    self.issues.append(CodeIssue(
                        file=rel_path,
                        line=node.lineno,
                        severity="medium",
                        category="design",
                        message=f"é–¢æ•° '{node.name}' ã®å¼•æ•°ãŒå¤šã™ãã¾ã™ ({num_args}å€‹)",
                        suggestion="å¼•æ•°ã‚’ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«ã¾ã¨ã‚ã‚‹ã“ã¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„"
                    ))
            
            # æ·±ã„ãƒã‚¹ãƒˆ
            if isinstance(node, (ast.If, ast.For, ast.While)):
                nest_level = self._get_nesting_level(node)
                if nest_level > 3:
                    self.issues.append(CodeIssue(
                        file=rel_path,
                        line=node.lineno,
                        severity="high",
                        category="complexity",
                        message=f"ãƒã‚¹ãƒˆãŒæ·±ã™ãã¾ã™ (ãƒ¬ãƒ™ãƒ« {nest_level})",
                        suggestion="æ—©æœŸãƒªã‚¿ãƒ¼ãƒ³ã‚„é–¢æ•°åˆ†å‰²ã§ãƒã‚¹ãƒˆã‚’æ¸›ã‚‰ã—ã¦ãã ã•ã„"
                    ))
    
    def _get_nesting_level(self, node: ast.AST, level: int = 0) -> int:
        """
        ãƒã‚¹ãƒˆãƒ¬ãƒ™ãƒ«ã‚’è¨ˆç®—
        
        Args:
            node: ASTãƒãƒ¼ãƒ‰
            level: ç¾åœ¨ã®ãƒ¬ãƒ™ãƒ«
            
        Returns:
            æœ€å¤§ãƒã‚¹ãƒˆãƒ¬ãƒ™ãƒ«
        """
        max_level = level
        
        for child in ast.iter_child_nodes(node):
            if isinstance(child, (ast.If, ast.For, ast.While, ast.With)):
                child_level = self._get_nesting_level(child, level + 1)
                max_level = max(max_level, child_level)
        
        return max_level
    
    def _detect_text_issues(self, lines: List[str], rel_path: str):
        """
        ãƒ†ã‚­ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹ã®å•é¡Œæ¤œå‡º
        
        Args:
            lines: ãƒ•ã‚¡ã‚¤ãƒ«è¡Œãƒªã‚¹ãƒˆ
            rel_path: ç›¸å¯¾ãƒ‘ã‚¹
        """
        for i, line in enumerate(lines, 1):
            # è¡Œã®é•·ã•ãƒã‚§ãƒƒã‚¯
            if len(line) > self.THRESHOLDS['max_line_length']:
                self.issues.append(CodeIssue(
                    file=rel_path,
                    line=i,
                    severity="low",
                    category="style",
                    message=f"è¡ŒãŒé•·ã™ãã¾ã™ ({len(line)}æ–‡å­— > {self.THRESHOLDS['max_line_length']}æ–‡å­—)",
                    suggestion=f"è¡Œã‚’{self.THRESHOLDS['max_line_length']}æ–‡å­—ä»¥å†…ã«åˆ†å‰²ã—ã¦ãã ã•ã„"
                ))
            
            # TODOã‚³ãƒ¡ãƒ³ãƒˆ
            if re.search(r'\b(TODO|FIXME|HACK|XXX)\b', line):
                self.issues.append(CodeIssue(
                    file=rel_path,
                    line=i,
                    severity="low",
                    category="todo",
                    message="TODO/FIXME/HACK/XXXã‚³ãƒ¡ãƒ³ãƒˆãŒæ®‹ã£ã¦ã„ã¾ã™",
                    suggestion="å¯¾å¿œäºˆå®šã®ä½œæ¥­ã‚’è¨ˆç”»ã—ã¦ãã ã•ã„"
                ))
            
            # ãƒ‡ãƒãƒƒã‚°printæ–‡ï¼ˆãŸã ã—ãƒ­ã‚®ãƒ³ã‚°ã¯é™¤å¤–ï¼‰
            stripped = line.strip()
            if stripped.startswith("print(") and "logger" not in line.lower() and "log" not in line.lower():
                # ãƒ¦ãƒ¼ã‚¶ãƒ¼å‘ã‘ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯é™¤å¤–
                if not any(keyword in line for keyword in ["===", "---", "âœ…", "âŒ", "ğŸ“Š", "ğŸ’¡"]):
                    self.issues.append(CodeIssue(
                        file=rel_path,
                        line=i,
                        severity="low",
                        category="debug",
                        message="ãƒ‡ãƒãƒƒã‚°ç”¨ã®printæ–‡ãŒæ®‹ã£ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™",
                        suggestion="ãƒ­ã‚¬ãƒ¼ã‚’ä½¿ç”¨ã™ã‚‹ã‹ã€ä¸è¦ã§ã‚ã‚Œã°å‰Šé™¤ã—ã¦ãã ã•ã„"
                    ))
    
    def _generate_report(self):
        """è§£æãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        print("\n" + "=" * 70)
        print("ğŸ“Š è§£æçµæœã‚µãƒãƒªãƒ¼")
        print("=" * 70)
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚µãƒãƒªãƒ¼
        total_loc = sum(m.lines_of_code for m in self.metrics)
        total_functions = sum(m.functions for m in self.metrics)
        total_classes = sum(m.classes for m in self.metrics)
        total_imports = sum(m.imports_count for m in self.metrics)
        avg_maintainability = sum(m.maintainability_index for m in self.metrics) / len(self.metrics) if self.metrics else 0
        max_complexity = max((m.complexity for m in self.metrics), default=0)
        
        print(f"\nğŸ“ˆ ã‚³ãƒ¼ãƒ‰ãƒ¡ãƒˆãƒªã‚¯ã‚¹:")
        print(f"  ç·ã‚³ãƒ¼ãƒ‰è¡Œæ•°: {total_loc:,}")
        print(f"  é–¢æ•°æ•°: {total_functions}")
        print(f"  ã‚¯ãƒ©ã‚¹æ•°: {total_classes}")
        print(f"  Importæ•°: {total_imports}")
        print(f"  å¹³å‡ä¿å®ˆæ€§æŒ‡æ¨™: {avg_maintainability:.1f}/100")
        print(f"  æœ€å¤§è¤‡é›‘åº¦: {max_complexity}")
        
        # å•é¡Œã‚µãƒãƒªãƒ¼
        severity_counts = {
            "critical": len([i for i in self.issues if i.severity == "critical"]),
            "high": len([i for i in self.issues if i.severity == "high"]),
            "medium": len([i for i in self.issues if i.severity == "medium"]),
            "low": len([i for i in self.issues if i.severity == "low"])
        }
        
        print(f"\nâš ï¸  æ¤œå‡ºã•ã‚ŒãŸå•é¡Œ:")
        print(f"  ğŸ”´ Critical: {severity_counts['critical']}")
        print(f"  ğŸŸ  High:     {severity_counts['high']}")
        print(f"  ğŸŸ¡ Medium:   {severity_counts['medium']}")
        print(f"  ğŸŸ¢ Low:      {severity_counts['low']}")
        print(f"  ğŸ“Š åˆè¨ˆ:     {len(self.issues)}")
        
        # é‡è¦ãªå•é¡Œã®ã¿è¡¨ç¤º
        critical_and_high = [i for i in self.issues if i.severity in ["critical", "high"]]
        medium_issues = [i for i in self.issues if i.severity == "medium"]
        
        if critical_and_high:
            print(f"\nğŸš¨ Critical/Highå•é¡Œ:")
            for issue in critical_and_high[:5]:
                print(f"\n  [{issue.severity.upper()}] {issue.file}:{issue.line}")
                print(f"    ğŸ“ {issue.message}")
                print(f"    ğŸ’¡ {issue.suggestion}")
        
        if medium_issues and not critical_and_high:
            print(f"\nâš ï¸  Mediumå•é¡Œï¼ˆä¸Šä½5ä»¶ï¼‰:")
            for issue in medium_issues[:5]:
                print(f"\n  [{issue.severity.upper()}] {issue.file}:{issue.line}")
                print(f"    ğŸ“ {issue.message}")
                print(f"    ğŸ’¡ {issue.suggestion}")
        
        # çµæœã‚’è¾æ›¸ã«ä¿å­˜
        self.analysis_result = {
            "timestamp": datetime.now().isoformat(),
            "thresholds": self.THRESHOLDS,
            "summary": {
                "total_loc": total_loc,
                "total_functions": total_functions,
                "total_classes": total_classes,
                "total_imports": total_imports,
                "avg_maintainability": round(avg_maintainability, 2),
                "max_complexity": max_complexity
            },
            "issues": {
                "total": len(self.issues),
                "by_severity": severity_counts
            },
            "metrics": [asdict(m) for m in self.metrics],
            "issues_detail": [asdict(i) for i in self.issues]
        }
    
    def export_report(self, output_path: Optional[Path] = None) -> str:
        """
        ãƒ¬ãƒãƒ¼ãƒˆã‚’JSONã§å‡ºåŠ›
        
        Args:
            output_path: å‡ºåŠ›ãƒ‘ã‚¹
            
        Returns:
            å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        if output_path is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_path = self.output_dir / f"code_analysis_{timestamp}.json"
        
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(self.analysis_result, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆã‚’å‡ºåŠ›ã—ã¾ã—ãŸ: {output_path}")
        return str(output_path)
    
    def get_recommendations(self) -> List[str]:
        """
        æ”¹å–„ææ¡ˆã‚’å–å¾—
        
        Returns:
            ææ¡ˆãƒªã‚¹ãƒˆ
        """
        recommendations = []
        
        # Critical/Highå•é¡Œ
        critical_issues = [i for i in self.issues if i.severity == "critical"]
        high_issues = [i for i in self.issues if i.severity == "high"]
        
        if critical_issues:
            recommendations.append(
                f"ğŸš¨ Criticalå•é¡ŒãŒ{len(critical_issues)}ä»¶ã‚ã‚Šã¾ã™ã€‚å³åº§ã«å¯¾å¿œã—ã¦ãã ã•ã„"
            )
        
        if high_issues:
            recommendations.append(
                f"ğŸ”´ Highå•é¡ŒãŒ{len(high_issues)}ä»¶ã‚ã‚Šã¾ã™ã€‚å„ªå…ˆçš„ã«å¯¾å¿œã—ã¦ãã ã•ã„"
            )
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ™ãƒ¼ã‚¹ã®ææ¡ˆ
        for metric in self.metrics:
            if metric.maintainability_index < self.THRESHOLDS['min_maintainability']:
                recommendations.append(
                    f"ğŸ“‰ {metric.file}: ä¿å®ˆæ€§ãŒä½ã„ã§ã™ ({metric.maintainability_index:.1f}/100)"
                )
            
            if metric.complexity > self.THRESHOLDS['max_complexity']:
                recommendations.append(
                    f"ğŸ”„ {metric.file}: è¤‡é›‘åº¦ãŒé«˜ã„ã§ã™ ({metric.complexity} > {self.THRESHOLDS['max_complexity']})"
                )
        
        return recommendations


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’å–å¾—
    project_root = Path(__file__).parent
    
    # è§£æå®Ÿè¡Œ
    analyzer = CodeAnalyzer(project_root)
    analyzer.analyze_project()
    
    # ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›
    analyzer.export_report()
    
    # æ¨å¥¨äº‹é …
    recommendations = analyzer.get_recommendations()
    if recommendations:
        print("\n" + "=" * 70)
        print("ğŸ’¡ æ”¹å–„ææ¡ˆ:")
        print("=" * 70)
        for rec in recommendations:
            print(f"  {rec}")
    else:
        print("\n" + "=" * 70)
        print("âœ¨ ã‚³ãƒ¼ãƒ‰å“è³ªã¯è‰¯å¥½ã§ã™ï¼")
        print("=" * 70)
    
    print("\n" + "=" * 70)
    print("âœ… è§£æå®Œäº†")
    print("=" * 70)


if __name__ == "__main__":
    main()
"""
Parts Model Module
éŸ³å£°ãƒ»ç”»åƒãƒ»è§£æãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¨ç®¡ç†

ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯å„ãƒ‘ãƒ¼ãƒ„ã‹ã‚‰å‘¼ã³å‡ºã•ã‚Œã€å¿…è¦ãªãƒ¢ãƒ‡ãƒ«ã‚’æä¾›ã—ã¾ã™
"""

import os
import requests
from pathlib import Path
from typing import Dict, Optional
import json


class PartsModel:
    """ãƒ¢ãƒ‡ãƒ«ç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    # ãƒ¢ãƒ‡ãƒ«å®šç¾©
    MODELS = {
        "chat": {
            "name": "claude-sonnet-4-20250514",
            "type": "chat",
            "provider": "anthropic"
        },
        "image_generation": {
            "name": "stable-diffusion-xl",
            "type": "image",
            "provider": "stability",
            "url": "https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0"
        },
        "speech_recognition": {
            "name": "whisper-base",
            "type": "audio",
            "provider": "openai",
            "url": "https://huggingface.co/openai/whisper-base"
        },
        "text_analysis": {
            "name": "bert-base-multilingual",
            "type": "nlp",
            "provider": "huggingface",
            "url": "https://huggingface.co/bert-base-multilingual-cased"
        },
        "emotion_detection": {
            "name": "emotion-english-distilroberta-base",
            "type": "nlp",
            "provider": "huggingface",
            "url": "https://huggingface.co/j-hartmann/emotion-english-distilroberta-base"
        }
    }
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.models_dir = Path(__file__).parent.parent.parent / "models"
        self.models_dir.mkdir(parents=True, exist_ok=True)
        
        self.cache_file = self.models_dir / "model_cache.json"
        self.loaded_models: Dict[str, any] = {}
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ãƒ­ãƒ¼ãƒ‰
        self._load_cache()
    
    def _load_cache(self):
        """ãƒ¢ãƒ‡ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ãƒ­ãƒ¼ãƒ‰"""
        if self.cache_file.exists():
            try:
                with open(self.cache_file, 'r', encoding='utf-8') as f:
                    self.model_cache = json.load(f)
            except Exception as e:
                print(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
                self.model_cache = {}
        else:
            self.model_cache = {}
    
    def _save_cache(self):
        """ãƒ¢ãƒ‡ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä¿å­˜"""
        try:
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(self.model_cache, f, indent=2)
        except Exception as e:
            print(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def get_model(self, model_key: str) -> Optional[str]:
        """
        ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’å–å¾—
        
        Args:
            model_key: ãƒ¢ãƒ‡ãƒ«ã‚­ãƒ¼ï¼ˆchat, image_generation, etc.ï¼‰
            
        Returns:
            ãƒ¢ãƒ‡ãƒ«åã¾ãŸã¯None
        """
        model_info = self.MODELS.get(model_key)
        if model_info:
            return model_info["name"]
        return None
    
    def get_chat_model(self) -> str:
        """ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—"""
        return self.MODELS["chat"]["name"]
    
    def get_image_model(self) -> str:
        """ç”»åƒç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—"""
        return self.MODELS["image_generation"]["name"]
    
    def get_speech_model(self) -> str:
        """éŸ³å£°èªè­˜ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—"""
        return self.MODELS["speech_recognition"]["name"]
    
    def get_analysis_model(self) -> str:
        """ãƒ†ã‚­ã‚¹ãƒˆè§£æãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—"""
        return self.MODELS["text_analysis"]["name"]
    
    def get_emotion_model(self) -> str:
        """æ„Ÿæƒ…æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—"""
        return self.MODELS["emotion_detection"]["name"]
    
    def download_model(self, model_key: str) -> bool:
        """
        ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        
        Args:
            model_key: ãƒ¢ãƒ‡ãƒ«ã‚­ãƒ¼
            
        Returns:
            æˆåŠŸæ™‚True
        """
        model_info = self.MODELS.get(model_key)
        if not model_info:
            print(f"âŒ ä¸æ˜ãªãƒ¢ãƒ‡ãƒ«: {model_key}")
            return False
        
        # URLãŒå­˜åœ¨ã—ãªã„å ´åˆï¼ˆAPIãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ï¼‰
        if "url" not in model_info:
            print(f"â„¹ï¸  {model_info['name']} ã¯APIãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ã§ã™")
            return True
        
        model_dir = self.models_dir / model_key
        model_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"ğŸ“¥ {model_info['name']} ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
        print(f"   URL: {model_info['url']}")
        
        try:
            # TODO: å®Ÿéš›ã®ãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Ÿè£…
            # ç¾åœ¨ã¯ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼
            placeholder_file = model_dir / "model_info.txt"
            with open(placeholder_file, 'w') as f:
                f.write(f"Model: {model_info['name']}\n")
                f.write(f"Type: {model_info['type']}\n")
                f.write(f"Provider: {model_info['provider']}\n")
                f.write(f"URL: {model_info.get('url', 'N/A')}\n")
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«è¨˜éŒ²
            self.model_cache[model_key] = {
                "name": model_info["name"],
                "path": str(model_dir),
                "downloaded": True
            }
            self._save_cache()
            
            print(f"âœ… {model_info['name']} ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†")
            return True
            
        except Exception as e:
            print(f"âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def download_all_models(self) -> Dict[str, bool]:
        """
        å…¨ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        
        Returns:
            å„ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰çµæœ
        """
        results = {}
        print("=" * 60)
        print("å…¨ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’é–‹å§‹ã—ã¾ã™")
        print("=" * 60)
        
        for model_key in self.MODELS.keys():
            results[model_key] = self.download_model(model_key)
        
        print("\n" + "=" * 60)
        print("ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰çµæœ:")
        for key, success in results.items():
            status = "âœ… æˆåŠŸ" if success else "âŒ å¤±æ•—"
            print(f"  {key}: {status}")
        print("=" * 60)
        
        return results
    
    def is_model_downloaded(self, model_key: str) -> bool:
        """
        ãƒ¢ãƒ‡ãƒ«ãŒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã‹ç¢ºèª
        
        Args:
            model_key: ãƒ¢ãƒ‡ãƒ«ã‚­ãƒ¼
            
        Returns:
            ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã®å ´åˆTrue
        """
        return model_key in self.model_cache and self.model_cache[model_key].get("downloaded", False)
    
    def get_model_info(self, model_key: str) -> Optional[Dict]:
        """
        ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’å–å¾—
        
        Args:
            model_key: ãƒ¢ãƒ‡ãƒ«ã‚­ãƒ¼
            
        Returns:
            ãƒ¢ãƒ‡ãƒ«æƒ…å ±è¾æ›¸
        """
        return self.MODELS.get(model_key)
    
    def get_all_models_info(self) -> Dict:
        """
        å…¨ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’å–å¾—
        
        Returns:
            å…¨ãƒ¢ãƒ‡ãƒ«ã®æƒ…å ±è¾æ›¸
        """
        return {
            "models": self.MODELS,
            "cache": self.model_cache,
            "models_dir": str(self.models_dir)
        }
    
    def clear_cache(self):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢"""
        self.model_cache.clear()
        self._save_cache()
        print("âœ… ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")
    
    def remove_model(self, model_key: str) -> bool:
        """
        ãƒ¢ãƒ‡ãƒ«ã‚’å‰Šé™¤
        
        Args:
            model_key: ãƒ¢ãƒ‡ãƒ«ã‚­ãƒ¼
            
        Returns:
            æˆåŠŸæ™‚True
        """
        model_dir = self.models_dir / model_key
        
        if model_dir.exists():
            try:
                import shutil
                shutil.rmtree(model_dir)
                
                if model_key in self.model_cache:
                    del self.model_cache[model_key]
                    self._save_cache()
                
                print(f"âœ… {model_key} ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
                return True
            except Exception as e:
                print(f"âŒ å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")
                return False
        else:
            print(f"â„¹ï¸  {model_key} ã¯å­˜åœ¨ã—ã¾ã›ã‚“")
            return False


# ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
_model_instance = None


def get_model_manager() -> PartsModel:
    """
    ãƒ¢ãƒ‡ãƒ«ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—
    
    Returns:
        PartsModelã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
    """
    global _model_instance
    if _model_instance is None:
        _model_instance = PartsModel()
    return _model_instance
